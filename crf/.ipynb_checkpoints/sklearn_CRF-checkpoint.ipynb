{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "import nltk\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import Doc\n",
    "from spacy.pipeline import Tagger\n",
    "import csv\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Read data:\n",
    "# data =[]\n",
    "# sents = []\n",
    "# file1 = open(\"./data/file42.txt.anns\",\"r\", encoding=\"utf8\")\n",
    "# file2 = open(\"./data/file43.txt.anns\",\"r\", encoding=\"utf8\")\n",
    "# file3 = open(\"./data/file44.txt.anns\",\"r\", encoding=\"utf8\")\n",
    "# file4 = open(\"./data/file45.txt.anns\",\"r\", encoding=\"utf8\")\n",
    "\n",
    "# for line in file1.readlines():\n",
    "#     data.append(line)\n",
    "# for line in file2.readlines():\n",
    "#     data.append(line)\n",
    "# for line in file3.readlines():\n",
    "#     data.append(line)\n",
    "# for line in file4.readlines():\n",
    "#     data.append(line)\n",
    "\n",
    "# c_sent = []\n",
    "# for line in data:\n",
    "#     if line == \"\\n\":\n",
    "#         if len(c_sent) > 0:\n",
    "#             sents.append(c_sent)\n",
    "#             c_sent = []\n",
    "#     else:\n",
    "#         c_sent.append((line.split(\" \")[0],line.split(\" \")[1].replace(\"\\n\",\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Get POS and DEP\n",
    "# final_res = []\n",
    "# for sent in sents:\n",
    "#     doc = Doc(nlp.vocab, words=[word[0] for word in sent])\n",
    "#     deps = nlp.parser(doc)\n",
    "#     tagger = nlp.tagger(doc)\n",
    "#     for i,word in enumerate(deps):\n",
    "#         final_res.append([word.text, tagger[i].pos_, word.dep_, word.head, sent[i][1]])\n",
    "#     final_res.append([0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Save file\n",
    "# import csv\n",
    "# with open(\"./data/data_POS_DEP.csv\",\"w\", encoding=\"utf8\") as outputf:\n",
    "#     writer = csv.writer(outputf)\n",
    "#     for line in final_res:\n",
    "#         writer.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read file\n",
    "raw_data = []\n",
    "with open(\"./data/data_POS_DEP.csv\", \"r\", encoding =\"utf8\") as inputf:\n",
    "    reader = csv.reader(inputf)\n",
    "    for line in reader:\n",
    "        raw_data.append(line)\n",
    "with open(\"./data/gen_data_POS_TAG.csv\", \"r\", encoding =\"utf8\") as inputf:\n",
    "    reader = csv.reader(inputf)\n",
    "    for line in reader:\n",
    "        raw_data.append(line)\n",
    "data = []\n",
    "tmp = []\n",
    "for line in raw_data:\n",
    "    if (str(line[1]) == \"0\"):\n",
    "        data.append(tmp)\n",
    "        tmp = []\n",
    "    else:\n",
    "        tmp.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent,i):\n",
    "    word = sent[i][0]\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': sent[i][1],\n",
    "        'dep' : sent[i][2],\n",
    "        'head' : sent[i][3],\n",
    "    }\n",
    "    \n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': sent[i-1][1],\n",
    "            '-1:dep': sent[i-1][2],\n",
    "            '-1:head' : sent[i-1][3]\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': sent[i+1][1],\n",
    "            '+1:dep': sent[i+1][2],\n",
    "            '+1:head' : sent[i+1][3]\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2features(sent):\n",
    "    return [word2features(sent,i) for i in range(len(sent))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2labels(sent):\n",
    "    return [word[4] for word in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sent2features(s) for s in data]\n",
    "y_train = [sent2labels(s) for s in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.3 s, sys: 0 ns, total: 11.3 s\n",
      "Wall time: 11.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.7467260106178021,\n",
    "    c2=0.012122583759942334,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 10.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 28s, sys: 5.54 s, total: 1min 33s\n",
      "Wall time: 10min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "# define fixed parameters and parameters to search\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
    "                        average='weighted', labels=labels)\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=50,\n",
    "                        scoring=f1_scorer)\n",
    "rs.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c1': 0.7467260106178021, 'c2': 0.012122583759942334}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model/crf_gen_model_10ktrain.sav']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save model\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "filename = './model/crf_gen_model_10ktrain.sav'\n",
    "joblib.dump(crf, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sents = [\"Mobile Applications and Device Management\"]\n",
    "data_test = []\n",
    "for sent in test_sents:\n",
    "    c_sent = []\n",
    "    doc = nlp(sent)\n",
    "    for i,word in enumerate(doc):\n",
    "        c_sent.append([word.text, word.pos_, word.dep_, word.head.text])\n",
    "    data_test.append(c_sent)\n",
    "    \n",
    "X_test = [sent2features(s) for s in data_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mobile B-SKILL\n",
      "Applications E-SKILL\n",
      "and O\n",
      "Device B-SKILL\n",
      "Management E-SKILL\n"
     ]
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "for i in range(len(y_pred[0])):\n",
    "    print(data_test[0][i][0],y_pred[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "# def print_state_features(state_features):\n",
    "#     for (attr, label), weight in state_features:\n",
    "#         print(\"%0.6f %-8s %s\" % (weight, label, attr))\n",
    "# print(\"Top positive:\")\n",
    "# print_state_features(Counter(crf.state_features_).most_common(30))\n",
    "# print(\"\\nTop negative:\")\n",
    "# print_state_features(Counter(crf.state_features_).most_common()[-30:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
